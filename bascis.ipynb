{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Camf5_v1ImmL",
        "outputId": "e1224f29-70f3-4051-c696-356a3c387578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "           1       0.00      0.00      0.00       1.0\n",
            "           2       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "Accuracy: 0.0\n",
            "Text: This product is a scam and you should avoid it at all costs!\n",
            "Predicted Class: 3 (0: Pos, 1: Neg, 2: Neu, 3: Prop)\n",
            "Probabilities: [0.22659507 0.27351382 0.20873888 0.29115215]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Install: pip install transformers torch scikit-learn\n",
        "# Optional CUDA Support for GPU : pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Model and Tokenizer (choose a suitable pre-trained model)\n",
        "model_name = \"distilbert-base-uncased\"  # Faster, good balance of speed and performance\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4) # 0: Positive, 1: Negative, 2: Neutral, 3: Propaganda\n",
        "\n",
        "texts = [\n",
        "    \"This product is amazing!\",  # Positive\n",
        "    \"This is a terrible experience.\",  # Negative\n",
        "    \"This is just a regular update.\",  # Neutral\n",
        "    \"Vote for X, they are the only ones who can save us!\",  # Propaganda\n",
        "    \"This is a lie spread by the enemy.\", #Propaganda\n",
        "    \"The weather is nice today.\", #Neutral\n",
        "    \"I am very disappointed with this service.\", #Negative\n",
        "    \"This movie is fantastic!\", #Positive\n",
        "]\n",
        "labels = [0, 1, 2, 3, 3, 2, 1, 0]\n",
        "\n",
        "# Tokenization and Data Splitting\n",
        "encoded_texts = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    encoded_texts[\"input_ids\"], labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Training Loop (simplified)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) #Use GPU if available\n",
        "\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "    optimizer.zero_grad()\n",
        "    input_ids = train_texts.to(device)\n",
        "    labels_tensor = torch.tensor(train_labels).to(device)\n",
        "    outputs = model(input_ids, labels=labels_tensor)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    input_ids = test_texts.to(device)\n",
        "    test_outputs = model(input_ids)\n",
        "    predictions = torch.argmax(test_outputs.logits, dim=-1).cpu().numpy()\n",
        "\n",
        "print(classification_report(test_labels, predictions))\n",
        "print(\"Accuracy:\", accuracy_score(test_labels, predictions))\n",
        "\n",
        "def analyze_text(text):\n",
        "    encoded_text = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_text)\n",
        "        probabilities = torch.nn.functional.softmax(output.logits, dim=-1)[0].cpu().numpy()\n",
        "        predicted_class = torch.argmax(output.logits, dim=-1).item()\n",
        "        return predicted_class, probabilities\n",
        "\n",
        "#Example usage\n",
        "text_to_analyze = \"This product is a scam and you should avoid it at all costs!\"\n",
        "predicted_class, probabilities = analyze_text(text_to_analyze)\n",
        "print(f\"Text: {text_to_analyze}\")\n",
        "print(f\"Predicted Class: {predicted_class} (0: Pos, 1: Neg, 2: Neu, 3: Prop)\")\n",
        "print(f\"Probabilities: {probabilities}\")"
      ]
    },
    {
      "source": [
        "!pip install dash plotly"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOYMw2ZAJRMg",
        "outputId": "30da0475-c074-493c-92e0-26ce5b49c663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Collecting Flask<3.1,>=1.0.4 (from dash)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting Werkzeug<3.1 (from dash)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting dash-html-components==2.0.0 (from dash)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.32.3)\n",
            "Collecting retrying (from dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (75.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.17.0)\n",
            "Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, Flask, dash\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "Successfully installed Flask-3.0.3 Werkzeug-3.0.6 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! pip install dash plotly\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Real-Time Broadcast Analysis\"),\n",
        "    dcc.Input(id=\"input-text\", type=\"text\", placeholder=\"Enter text to analyze...\"),\n",
        "    html.Div(id=\"analysis-results\"),\n",
        "    dcc.Graph(id=\"probabilities-graph\"),\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    [dash.dependencies.Output(\"analysis-results\", \"children\"),\n",
        "     dash.dependencies.Output(\"probabilities-graph\", \"figure\")],\n",
        "    [dash.dependencies.Input(\"input-text\", \"value\")],\n",
        ")\n",
        "def update_analysis(input_text):\n",
        "    if input_text:\n",
        "        predicted_class, probabilities = analyze_text(input_text)\n",
        "        class_names = [\"Positive\", \"Negative\", \"Neutral\", \"Propaganda\"]\n",
        "        result_text = f\"Analysis: {input_text} - Predicted Class: {class_names[predicted_class]}\"\n",
        "        fig = go.Figure(data=[go.Bar(x=class_names, y=probabilities)])\n",
        "        return result_text, fig\n",
        "    else:\n",
        "        return \"\", go.Figure()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "Tb7BpKUEIqq-",
        "outputId": "e3c40387-5542-4448-8ae4-4102bd813138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import dash\n",
        "from dash import dcc, html, Output, Input\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# ... (Your existing code for model loading, data preparation, and training) ...\n",
        "\n",
        "def analyze_text(text):\n",
        "    # ... (Your existing analyze_text function) ...\n",
        "    # The following lines were not indented properly:\n",
        "    encoded_text = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    # Add attention_mask to the model call\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_text) # Pass encoded_text as a dictionary\n",
        "        probabilities = torch.nn.functional.softmax(output.logits, dim=-1)[0].cpu().numpy()\n",
        "        predicted_class = torch.argmax(output.logits, dim=-1).item()\n",
        "        return predicted_class, probabilities\n",
        "\n",
        "\n",
        "# Dash App Improvements\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"Real-Time Text Analysis\"),  # Clearer title\n",
        "    dcc.Input(id=\"input-text\", type=\"text\", placeholder=\"Enter text here...\", style={'width': '80%'}), # Wider input\n",
        "    html.Div(id=\"analysis-results\", style={'margin-top': '20px'}),  # Add margin\n",
        "    dcc.Graph(id=\"probabilities-graph\", style={'height': '400px'}), # Fixed height\n",
        "    html.Div(id='output-prediction') # Add a new output for the predicted class\n",
        "])\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [Output(\"analysis-results\", \"children\"),\n",
        "     Output(\"probabilities-graph\", \"figure\"),\n",
        "     Output('output-prediction', 'children')], # Add the new output\n",
        "    Input(\"input-text\", \"value\"),\n",
        ")\n",
        "def update_analysis(input_text):\n",
        "    if input_text:\n",
        "        predicted_class, probabilities = analyze_text(input_text)\n",
        "        class_names = [\"Positive\", \"Negative\", \"Neutral\", \"Propaganda\"]\n",
        "\n",
        "        # Improved output formatting\n",
        "        result_text = html.Div([\n",
        "            html.H3(f\"Analysis of: '{input_text}'\"),\n",
        "            html.P(f\"Predicted Class: {class_names[predicted_class]}\"), # Show class name\n",
        "        ])\n",
        "\n",
        "        # Enhanced bar chart\n",
        "        fig = go.Figure(data=[go.Bar(x=class_names, y=probabilities, marker_color=['green', 'red', 'blue', 'orange'])])\n",
        "        fig.update_layout(title_text=\"Class Probabilities\", xaxis_title=\"Class\", yaxis_title=\"Probability\")\n",
        "\n",
        "        # Output for the predicted class\n",
        "        predicted_class_output = html.H4(f\"Predicted Class: {class_names[predicted_class]}\")\n",
        "\n",
        "        return result_text, fig, predicted_class_output\n",
        "    else:\n",
        "        return \"\", go.Figure(), \"\" # Return empty string for the new output as well\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run_server(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "d_I_DWdjJmYT",
        "outputId": "b1e96d73-6d33-400c-b0cd-cf34cff6b194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}